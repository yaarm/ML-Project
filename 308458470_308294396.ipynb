{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "308458470_308294396.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Mkmv9wo9SYQj",
        "-UOVak5VR8sf",
        "r5jIYlIoSM2l"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy6Ef5CVyphO"
      },
      "source": [
        "**Imports and installations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xW5ShSxCvZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "689eb341-06cc-4cce-a480-c6d417f61f3f"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import accuracy_score, precision_score, roc_curve, auc, confusion_matrix, precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/keras-idiomatic-programmer/master/zoo/resnet/resnet_cifar10.py\n",
        "import resnet_cifar10\n",
        "!pip install optuna\n",
        "import optuna\n",
        "import xlwt\n",
        "from xlwt import Workbook\n",
        "wb = Workbook()\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from keras import backend as K \n",
        "import time\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# Random seed fixation\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-17 08:48:05--  https://raw.githubusercontent.com/GoogleCloudPlatform/keras-idiomatic-programmer/master/zoo/resnet/resnet_cifar10.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6064 (5.9K) [text/plain]\n",
            "Saving to: ‘resnet_cifar10.py’\n",
            "\n",
            "\rresnet_cifar10.py     0%[                    ]       0  --.-KB/s               \rresnet_cifar10.py   100%[===================>]   5.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-17 08:48:05 (58.0 MB/s) - ‘resnet_cifar10.py’ saved [6064/6064]\n",
            "\n",
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/18/b49ca91cf592747e19f2d333c2a86cd7c81895b922a5a09adf6335471576/optuna-2.8.0-py3-none-any.whl (301kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.20)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/11/aea1cacbd4cf8262809c4d6f95dcb3f2802594de1f51c5bd454d69bf15c5/cliff-3.8.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/80/ef186e599a57d0e4cb78fc76e0bfc2e6953fa9716b2a5cf2de0117ed8eb5/alembic-1.6.5-py2.py3-none-any.whl (164kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 16.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.6.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 23.8MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/ca/d407811641ec1d8bd8a38ee3165d73aa44776d7700436bd4d4a6606f2736/cmd2-2.1.2-py3-none-any.whl (141kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 20.8MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from PrettyTable>=0.7.2->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11136 sha256=694f297395569f72a74fdce8a5ee4c5ac96a62efa87328acde6bb654a1f94f93\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: cmaes, pbr, stevedore, pyperclip, colorama, cmd2, cliff, colorlog, python-editor, Mako, alembic, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.6.5 cliff-3.8.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-5.0.1 optuna-2.8.0 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkmv9wo9SYQj"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2ny5lDcddD7"
      },
      "source": [
        "**Deep Ensemble model:**\n",
        "\n",
        "In this section we'll define the Deep Ensemble model. This is a model that contains several deep networks that combined to one model using ensemble learning method. It defines the fit and predict methods. The predict function aggregate the results from the different deep networks using argmax.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohgYKu6_gWhP"
      },
      "source": [
        "class DeepEnsemble(BaseEstimator):\n",
        "    # init the model members\n",
        "    def __init__(self):\n",
        "        self.dictionary = {'ensemble_members': []}\n",
        "        members = []\n",
        "        # go over the different models\n",
        "        for i in range(3):\n",
        "          # Create model\n",
        "          model = get_training_model()\n",
        "          members.append(model)\n",
        "        self.dictionary['ensemble_members'] = members\n",
        "        \n",
        "    # set optimizer for the model members\n",
        "    def set_model_params(self, opt):\n",
        "      for member in self.dictionary['ensemble_members']:\n",
        "        member.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "    # fit the model members\n",
        "    def fit(self, train_ds, val_ds):\n",
        "      for model in self.dictionary['ensemble_members']:    \n",
        "        model.fit(train_ds, validation_data=val_ds, epochs=3, verbose=0)\n",
        "\n",
        "      return self.dictionary\n",
        "\n",
        "    # predict the classes using aggregation of the results from the members\n",
        "    def predict(self, x):\n",
        "      # make predictions\n",
        "      yhats = [model.predict(x/255.) for model in self.dictionary['ensemble_members']]\n",
        "      yhats = np.array(yhats)\n",
        "      # sum across ensemble members\n",
        "      summed = np.sum(yhats, axis=0)\n",
        "      # argmax across classes\n",
        "      result = np.argmax(summed, axis=1)\n",
        "      return result\n",
        "\n",
        "    # predict the classes probabilities using aggregation of the results from the members\n",
        "    def predict_proba(self, x):\n",
        "      # make predictions\n",
        "      yhats = [model.predict(x/255.) for model in self.dictionary['ensemble_members']]\n",
        "      yhats = np.array(yhats)\n",
        "      # sum across ensemble members\n",
        "      summed = np.sum(yhats, axis=0)\n",
        "      # normalize probabilites\n",
        "      for i in range(len(summed)):\n",
        "        sum = np.sum(summed[i])\n",
        "        for j in range(len(summed[i])):\n",
        "          summed[i][j] = summed[i][j] / sum\n",
        "\n",
        "      return summed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9ZByPnTNyxI"
      },
      "source": [
        "**Improved Deep Ensemble model:**\n",
        "\n",
        "In order to improve the Deep Ensemble model, we used the Boosting technique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPXBCysEVfHY"
      },
      "source": [
        "class ImprovedDeepEnsemble(BaseEstimator):\n",
        "    # init the model members\n",
        "    def __init__(self):\n",
        "        self.dictionary = {'ensemble_members': []}\n",
        "        members = []\n",
        "        # go over the different models\n",
        "        for i in range(3):         \n",
        "          # Create model\n",
        "          model = get_training_model()\n",
        "          members.append(model)\n",
        "        self.dictionary['ensemble_members'] = members        \n",
        "\n",
        "    # set optimizer for the model members\n",
        "    def set_model_params(self, opt):\n",
        "      for member in self.dictionary['ensemble_members']:\n",
        "        member.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "    # predict the class probabilities\n",
        "    def predict_proba(self, x_test, y_test):\n",
        "      y_pred_final = pd.DataFrame()\n",
        "      y_test_final = pd.DataFrame()\n",
        "      y_test = pd.DataFrame(y_test)\n",
        "\n",
        "      for model in self.dictionary['ensemble_members']:    \n",
        "        # predict and find the max probability\n",
        "        y_pred_prob = pd.DataFrame(model.predict(x_test/255.))\n",
        "        y_pred_prob_max = pd.DataFrame(y_pred_prob.max(axis=1))\n",
        "\n",
        "        # find indexes of samples that pass and didn't pass the threshold\n",
        "        under_threshold_indexes = pd.Index(y_pred_prob_max[y_pred_prob_max[0] < 0.6].index.tolist())\n",
        "        all_indexes = pd.Index(y_pred_prob.index)\n",
        "        over_threshold_indexes = all_indexes.difference(under_threshold_indexes)\n",
        "\n",
        "\n",
        "        # add pred results of test samples that pass the threshold\n",
        "        rows = y_pred_prob.iloc[over_threshold_indexes]\n",
        "        y_pred_final = y_pred_final.append(rows)\n",
        "        y_test_final = y_test_final.append(y_test.iloc[over_threshold_indexes])\n",
        "\n",
        "        # stop the training if all samples pass the required threshold\n",
        "        if len(under_threshold_indexes) == 0:\n",
        "          break\n",
        "        # define the test set again\n",
        "        else:\n",
        "          x_test = x_test[under_threshold_indexes]\n",
        "          y_test = y_test.iloc[under_threshold_indexes]\n",
        "      \n",
        "      # predict the left test set\n",
        "      if len(under_threshold_indexes) > 0:\n",
        "          rows = y_pred_prob.iloc[under_threshold_indexes]\n",
        "          y_pred_final = y_pred_final.append(rows)\n",
        "          y_test_final = y_test_final.append(y_test)\n",
        "\n",
        "\n",
        "      y_test_final = y_test_final.values.tolist()\n",
        "      y_test_final = np.array(y_test_final)\n",
        "      y_pred_final = y_pred_final.to_numpy()\n",
        "\n",
        "      return y_test_final, y_pred_final\n",
        "\n",
        "    # fit and predict the classes probabilities\n",
        "    def fit_predict(self, train_ds, val_ds, x_test, y_test):\n",
        "      total_training_time = 0\n",
        "      total_predicting_time = 0\n",
        "      y_pred_final = pd.DataFrame()\n",
        "      y_test_final = pd.DataFrame()\n",
        "      y_test = pd.DataFrame(y_test)\n",
        "\n",
        "      for model in self.dictionary['ensemble_members']:    \n",
        "        # fit the model\n",
        "        start = time.time()\n",
        "        model.fit(train_ds, validation_data=val_ds, epochs=3, verbose=0)\n",
        "        end = time.time()\n",
        "        total_training_time = total_training_time + (end - start)\n",
        "\n",
        "        # predict and find the max probability\n",
        "        start = time.time()\n",
        "        y_pred_prob = pd.DataFrame(model.predict(x_test/255.))\n",
        "        end = time.time()\n",
        "        total_predicting_time = total_predicting_time + (end - start)\n",
        "        y_pred_prob_max = pd.DataFrame(y_pred_prob.max(axis=1))\n",
        "\n",
        "        # find indexes of samples that pass and didn't pass the threshold\n",
        "        under_threshold_indexes = pd.Index(y_pred_prob_max[y_pred_prob_max[0] < 0.6].index.tolist())\n",
        "        all_indexes = pd.Index(y_pred_prob.index)\n",
        "        over_threshold_indexes = all_indexes.difference(under_threshold_indexes)\n",
        "\n",
        "\n",
        "        # add pred results of test samples that pass the threshold\n",
        "        rows = y_pred_prob.iloc[over_threshold_indexes]\n",
        "        y_pred_final = y_pred_final.append(rows)\n",
        "        y_test_final = y_test_final.append(y_test.iloc[over_threshold_indexes])\n",
        "\n",
        "        # stop the training if all samples pass the required threshold\n",
        "        if len(under_threshold_indexes) == 0:\n",
        "          break\n",
        "        # define the test set again\n",
        "        else:\n",
        "          x_test = x_test[under_threshold_indexes]\n",
        "          y_test = y_test.iloc[under_threshold_indexes]\n",
        "      \n",
        "      # predict the left test set\n",
        "      if len(under_threshold_indexes) > 0:\n",
        "          rows = y_pred_prob.iloc[under_threshold_indexes]\n",
        "          y_pred_final = y_pred_final.append(rows)\n",
        "          y_test_final = y_test_final.append(y_test)\n",
        "\n",
        "\n",
        "      y_test_final = y_test_final.values.tolist()\n",
        "      y_test_final = np.array(y_test_final)\n",
        "      y_pred_final = y_pred_final.to_numpy()\n",
        "\n",
        "      # return results\n",
        "      return y_test_final, y_pred_final, total_training_time, total_predicting_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBT7lV3ORkp4"
      },
      "source": [
        "**Help functions:**\n",
        "\n",
        "In this section there are the following functions:\n",
        "\n",
        "* get_training_model - return instance of ResNet model\n",
        "* normalize - converts the samples to be represented in float32 form\n",
        "* augment - adding data augmentation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxLXsoIca1w7"
      },
      "source": [
        "# return instance of ResNet model\n",
        "def get_training_model():\n",
        "    # ResNet20\n",
        "    n = 2\n",
        "    depth =  n * 9 + 2\n",
        "    n_blocks = ((depth - 2) // 9) - 1\n",
        "\n",
        "    # The input tensor\n",
        "    inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "    # The Stem Convolution Group\n",
        "    x = resnet_cifar10.stem(inputs)\n",
        "\n",
        "    # The learner\n",
        "    x = resnet_cifar10.learner(x, n_blocks)\n",
        "\n",
        "    # The Classifier for 10 classes\n",
        "    outputs = resnet_cifar10.classifier(x, 10)\n",
        "\n",
        "    # Instantiate the Model\n",
        "    model = Model(inputs, outputs)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# the function converts the samples to be represented in float32 form\n",
        "def normalize(image, label):\n",
        "    return tf.image.convert_image_dtype(image, tf.float32), label\n",
        "\n",
        "# Adding data augmentation\n",
        "def augment(image,label):\n",
        "    image = tf.image.resize_with_crop_or_pad(image, 40, 40) # Add 8 pixels of padding\n",
        "    image = tf.image.random_crop(image, size=[32, 32, 3]) # Random crop back to 32x32\n",
        "    image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n",
        "    image = tf.clip_by_value(image, 0., 1.)\n",
        "    \n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UOVak5VR8sf"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jHN6XivzFhI"
      },
      "source": [
        "**Load datasets:**\n",
        "\n",
        "In this section we will first load the CIFAR10 dataset. Then, we will split it to smaller subsets that will be used as different datasets for the next phase. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTAOu8OBdbpw"
      },
      "source": [
        "SUBSET_NUM = 120\n",
        "\n",
        "# The function receives X and y sets and split them to 10 datasets \n",
        "def split_dataset_by_subset_num(X, y):\n",
        "  return np.split(X, SUBSET_NUM), np.split(y, SUBSET_NUM)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NdU2S_4a_cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b63303c-4a80-4d04-891e-b707e758bb4e"
      },
      "source": [
        "# Load the training and testing sets of CIFAR10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Concatenate train and test images\n",
        "X = np.concatenate((x_train,x_test), axis=0)\n",
        "y = np.concatenate((y_train,y_test), axis=0)\n",
        "\n",
        "# split the sets to small datasets\n",
        "X_subsets, y_subsets = split_dataset_by_subset_num(X, y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5jIYlIoSM2l"
      },
      "source": [
        "# Cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIDm5y0eS81p"
      },
      "source": [
        "In this section we defined the different functions that required for the optimization process - using Optuna library. We created two functions for each algorithm - one for creating the train objective that finds the best parameters of the model according to the accuracy score. The second one - evaluate objective, which uses the best parameters found in the train, in order to evaluate the different metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL5TLOHbJ5mc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5b3d6d-0b98-40ea-f375-a8ccffdafaef"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "!pip install pycm\n",
        "from pycm import ConfusionMatrix\n",
        "from numpy import mean, std\n",
        "import warnings\n",
        "\n",
        "# constants \n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# the function returns the base model of InceptionV3 without the top layer \n",
        "def get_inception_model():\n",
        "  pre_trained_model = InceptionV3(include_top = False, weights = 'imagenet', input_shape=(128, 128, 3))\n",
        "  pre_trained_model.trainable = False\n",
        "  return pre_trained_model\n",
        "\n",
        "# the function creates an objective of Deep Ensemble model and returns the best accuracy score\n",
        "def deep_ens_train_objective(trial, train_ds, val_ds, x_test, y_test):\n",
        "  K.clear_session()\n",
        "  model = DeepEnsemble()\n",
        "  optimizer_options = [\"Adam\", \"RMSprop\"]\n",
        "  optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n",
        "  if optimizer_selected == \"RMSprop\":\n",
        "      lr = trial.suggest_float(\"rmsprop_learning_rate\", (1.6*1e-3)/8, 1.6*1e-3, log=True)\n",
        "      opt = RMSprop(learning_rate=lr)\n",
        "  elif optimizer_selected == \"Adam\":\n",
        "      lr = trial.suggest_float(\"adam_learning_rate\", (1.6*1e-3)/8, 1.6*1e-3, log=True)\n",
        "      opt = Adam(learning_rate=lr)\n",
        "\n",
        "  model.set_model_params(opt)\n",
        "\n",
        "  # train the model\n",
        "  model.fit(train_ds, val_ds)\n",
        "  # predict and calculate accuracy\n",
        "  yhat = model.predict(x_test)\n",
        "  accuracy = accuracy_score(y_test, yhat)\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "# the function creates an objective of Improved Deep Ensemble model and returns the best accuracy score\n",
        "def improved_deep_ens_train_objective(trial, train_ds, val_ds, x_test, y_test):\n",
        "  K.clear_session()\n",
        "  model = ImprovedDeepEnsemble()\n",
        "  optimizer_options = [\"Adam\", \"RMSprop\"]\n",
        "  optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n",
        "  if optimizer_selected == \"RMSprop\":\n",
        "      lr = trial.suggest_float(\"rmsprop_learning_rate\", (1.6*1e-3)/8, 1.6*1e-3, log=True)\n",
        "      opt = RMSprop(learning_rate=lr)\n",
        "  elif optimizer_selected == \"Adam\":\n",
        "      lr = trial.suggest_float(\"adam_learning_rate\", (1.6*1e-3)/8, 1.6*1e-3, log=True)\n",
        "      opt = Adam(learning_rate=lr)\n",
        "\n",
        "  model.set_model_params(opt)\n",
        "\n",
        "  # train the model and predict\n",
        "  y_test, yhat, total_training_time, total_predicting_time = model.fit_predict(train_ds, val_ds, x_test, y_test)\n",
        "  yhat = np.argmax(yhat, axis=1)\n",
        "  # calculate accuracy\n",
        "  accuracy = accuracy_score(y_test, yhat)\n",
        "\n",
        "  return accuracy  \n",
        "\n",
        "# the function receives the y_test, y classes probabilities and y probabilities and y_test_binary and returns the following metrics: \n",
        "# accuracy, TPR, FPR, precision, roc_auc, auc_PR_curve\n",
        "def evaluate_metrics(y_test, yhat, y_probs, y_test_binary):\n",
        "  accuracy = accuracy_score(y_test, yhat)\n",
        "\n",
        "  # calculate TPR & FPR\n",
        "  cm = ConfusionMatrix(actual_vector=y_test, predict_vector=yhat)\n",
        "  TPR = cm.overall_stat['TPR Micro']\n",
        "  FPR = cm.overall_stat['FPR Micro']\n",
        "\n",
        "  # calculate auc under PR curve\n",
        "  average_precision = dict()\n",
        "  average_precision[\"micro\"] = average_precision_score(y_test_binary, y_probs, average=\"micro\")\n",
        "\n",
        "  # calculate precision\n",
        "  precision = precision_score(y_test, yhat, average=\"micro\")\n",
        "\n",
        "  # calculate auc\n",
        "  roc_auc = roc_auc_score(y_test, y_probs, multi_class='ovr')\n",
        "\n",
        "  return accuracy, TPR, FPR, precision, roc_auc, average_precision[\"micro\"]\n",
        "\n",
        "# the function receives the y_test, y classes probabilities and y probabilities and y_test_binary and calculate the metrics for the improved algorithm \n",
        "# the metrics: accuracy, TPR, FPR, precision, roc_auc, auc_PR_curve\n",
        "def evaluate_metrics_improved_deep(y_test, yhat, y_probs, y_test_binary, y_test_probs):\n",
        "  accuracy = accuracy_score(y_test, yhat)\n",
        "\n",
        "  # calculate TPR & FPR\n",
        "  cm = ConfusionMatrix(actual_vector=y_test, predict_vector=yhat)\n",
        "  TPR = cm.overall_stat['TPR Micro']\n",
        "  FPR = cm.overall_stat['FPR Micro']\n",
        "\n",
        "  # calculate auc under PR curve\n",
        "  average_precision = dict()\n",
        "  average_precision[\"micro\"] = average_precision_score(y_test_binary, y_probs, average=\"micro\")\n",
        "\n",
        "  # calculate precision\n",
        "  precision = precision_score(y_test, yhat, average=\"micro\")\n",
        "\n",
        "  # calculate auc\n",
        "  roc_auc = roc_auc_score(y_test_probs, y_probs, multi_class='ovr')\n",
        "\n",
        "  return accuracy, TPR, FPR, precision, roc_auc, average_precision[\"micro\"]\n",
        "\n",
        "# the function creates an objective with the best trial of the Deep Ensemble model and evaluate the different metrics\n",
        "def deep_ens_evaluate_objective(trial, train_ds, val_ds, x_test, y_test):\n",
        "  K.clear_session()\n",
        "  model = DeepEnsemble()\n",
        "  optimizer_options = [\"Adam\", \"RMSprop\"]\n",
        "  optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n",
        "  if optimizer_selected == \"RMSprop\":\n",
        "      lr = trial.suggest_float(\"rmsprop_learning_rate\", (1.6*1e-3)/8, 1.6*1e-3, log=True)\n",
        "      opt = RMSprop(learning_rate=lr)\n",
        "  elif optimizer_selected == \"Adam\":\n",
        "      lr = trial.suggest_float(\"adam_learning_rate\", (1.6*1e-3)/8, 1.6*1e-3, log=True)\n",
        "      opt = Adam(learning_rate=lr)\n",
        "\n",
        "  model.set_model_params(opt)\n",
        "  \n",
        "  # calculate fit runtime\n",
        "  start = time.time()\n",
        "  model.fit(train_ds, val_ds)\n",
        "  end = time.time()\n",
        "  training_time = end - start\n",
        "\n",
        "  # calculate inference time\n",
        "  start = time.time()\n",
        "  yhat = model.predict(x_test)\n",
        "  end = time.time()\n",
        "  inference_time = (end - start)\n",
        "\n",
        "  # Binarize the output\n",
        "  y_test_binary = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5, 6 , 7, 8, 9])\n",
        "  y_probs = model.predict_proba(x_test)\n",
        "\n",
        "  # evaluate metrics\n",
        "  accuracy, TPR, FPR, precision, roc_auc, PR_curve_auc = evaluate_metrics(y_test, yhat, y_probs, y_test_binary)\n",
        "\n",
        "  return accuracy, TPR, FPR, precision, roc_auc, PR_curve_auc, training_time, inference_time\n",
        "\n",
        "\n",
        "# the function creates an objective with the best trial of the Improved Deep Ensemble model and evaluate the different metrics\n",
        "def improved_deep_ens_evaluate_objective(trial, train_ds, val_ds, x_test, y_test):\n",
        "  K.clear_session()\n",
        "  model = ImprovedDeepEnsemble()\n",
        "  optimizer_options = [\"Adam\", \"RMSprop\"]\n",
        "  optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n",
        "  if optimizer_selected == \"RMSprop\":\n",
        "      lr = trial.suggest_float(\"rmsprop_learning_rate\", (1.6*1e-3)/8, 1.6*1e-3, log=True)\n",
        "      opt = RMSprop(learning_rate=lr)\n",
        "  elif optimizer_selected == \"Adam\":\n",
        "      lr = trial.suggest_float(\"adam_learning_rate\", (1.6*1e-3)/8, 1.6*1e-3, log=True)\n",
        "      opt = Adam(learning_rate=lr)\n",
        "\n",
        "  model.set_model_params(opt)\n",
        "  \n",
        "  # calculate fit runtime\n",
        "  y_test, yhat, total_training_time, total_predicting_time = model.fit_predict(train_ds, val_ds, x_test, y_test)\n",
        "  yhat = np.argmax(yhat, axis=1)\n",
        "\n",
        "  # Binarize the output\n",
        "  y_test_probs, y_probs = model.predict_proba(x_test, y_test)\n",
        "  y_test_binary = label_binarize(y_test_probs, classes=[0, 1, 2, 3, 4, 5, 6 , 7, 8, 9])\n",
        "\n",
        "  # evaluate metrics\n",
        "  accuracy, TPR, FPR, precision, roc_auc, PR_curve_auc = evaluate_metrics_improved_deep(y_test, yhat, y_probs, y_test_binary, y_test_probs)\n",
        "\n",
        "  return accuracy, TPR, FPR, precision, roc_auc, PR_curve_auc, total_training_time, total_predicting_time\n",
        "\n",
        "# the function creates an objective of Inception model and returns the best accuracy score\n",
        "def inception_train_objective(trial, train_ds, val_ds, x_test, y_test):\n",
        "  K.clear_session()\n",
        "  pre_trained_model = get_inception_model()\n",
        "  rate = trial.suggest_float(\"rate\", 0.4, 0.6)\n",
        "\n",
        "  model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=(32, 32, 3)),\n",
        "        tf.keras.layers.UpSampling2D((2,2)),\n",
        "        tf.keras.layers.UpSampling2D((2,2)),\n",
        "        pre_trained_model,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(rate=rate),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ] \n",
        "  )\n",
        "\n",
        "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
        "  model.compile(optimizer=tf.optimizers.Adam(lr=lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=30, restore_best_weights=True)\n",
        "  model.fit(train_ds, epochs=3, verbose=0, validation_data=val_ds, callbacks=[early_stopping])\n",
        "  yhat = model.predict_classes(x_test)\n",
        "  accuracy = accuracy_score(y_test, yhat)\n",
        "  return accuracy\n",
        "\n",
        "# the function creates an objective with the best trial of the Inception model and evaluate the different metrics\n",
        "def inception_evaluate_objective(trial, train_ds, val_ds, x_test, y_test):\n",
        "  K.clear_session()\n",
        "  pre_trained_model = get_inception_model()\n",
        "  rate = trial.suggest_float(\"rate\", 0.4, 0.6)\n",
        "\n",
        "  model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=(32, 32, 3)),\n",
        "        tf.keras.layers.UpSampling2D((2,2)),\n",
        "        tf.keras.layers.UpSampling2D((2,2)),\n",
        "        pre_trained_model,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(rate=rate),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ] \n",
        "  )\n",
        "\n",
        "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
        "  model.compile(optimizer=tf.optimizers.Adam(lr=lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=30, restore_best_weights=True)\n",
        "\n",
        "  # calculate fit runtime\n",
        "  start = time.time()\n",
        "  model.fit(train_ds, epochs=3, verbose=0, validation_data=val_ds, callbacks=[early_stopping])\n",
        "  end = time.time()\n",
        "  training_time = end - start\n",
        "\n",
        "  # calculate inference time\n",
        "  start = time.time()\n",
        "  yhat = model.predict_classes(x_test)\n",
        "  end = time.time()\n",
        "  inference_time = (end - start)\n",
        "\n",
        "\n",
        "  # Binarize the output\n",
        "  y_test_binary = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5, 6 , 7, 8, 9])\n",
        "  y_probs = model.predict_proba(x_test)\n",
        "\n",
        "  # evaluate metrics\n",
        "  accuracy, TPR, FPR, precision, roc_auc, PR_curve_auc = evaluate_metrics(y_test, yhat, y_probs, y_test_binary)\n",
        "\n",
        "  return accuracy, TPR, FPR, precision, roc_auc, PR_curve_auc, training_time, inference_time\n",
        "\n",
        "def initiate_report_df():\n",
        "  report_df = pd.DataFrame(columns=['Dataset Name','Algorithm Name','Cross Validation',\n",
        "                             'Hyper-Parameters Values','Accuracy','TPR','FPR',\n",
        "                             'Precision','AUC','PR-Curve','Training Time','Inference Time'])\n",
        "  return report_df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/c4/a05b90819dcf7e50bdddb030238a771bf87b0695e6c47a247f66ab7ed5d0/pycm-3.1-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.7MB/s \n",
            "\u001b[?25hCollecting art>=1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/74/55552eaad673dc81546d1386161e6cd8f7edf951690de82df822fe46541d/art-5.2-py2.py3-none-any.whl (571kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pycm) (1.19.5)\n",
            "Installing collected packages: art, pycm\n",
            "Successfully installed art-5.2 pycm-3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su7wL59dTwwY"
      },
      "source": [
        "**Cross validation:**\n",
        "\n",
        "In this section we defined the nested_cross_validation function that does 10 outer cross validation, 3 inner cross validation for the hyper-parameters optimization (with 10 trials for each run)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZKBnmRv32h-"
      },
      "source": [
        "# the function creates the train and validation sets\n",
        "def create_train_and_val_sets(x_train, y_train, train_j, val_j):\n",
        "  #create the train dataset\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train[train_j], y_train[train_j]))\n",
        "  train_ds = (\n",
        "      train_ds\n",
        "      .shuffle(1024)\n",
        "      .map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "      .map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  )   \n",
        "\n",
        "  #create the validation dataset\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((x_train[val_j], y_train[val_j]))\n",
        "  val_ds = (\n",
        "      val_ds\n",
        "      .map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  )\n",
        "\n",
        "  return train_ds, val_ds\n",
        "\n",
        "def nested_cross_validation(X, Y, dataset_name, model_name, report_df):\n",
        "  with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    # configure the cross-validation procedure - outer\n",
        "    cv_outer = StratifiedKFold(n_splits=10, shuffle=False)\n",
        "    # enumerate splits\n",
        "    outer_results = list()\n",
        "    cv_counter = 1\n",
        "    for train_i, test_i in cv_outer.split(X, Y):\n",
        "      x_train = X[train_i]\n",
        "      y_train = Y[train_i]\n",
        "      x_test = X[test_i]\n",
        "      y_test = Y[test_i]\n",
        "      # configure the cross-validation procedure - inner\n",
        "      cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "      for train_j, val_j in cv_inner.split(x_train, y_train):\n",
        "        train_ds, val_ds = create_train_and_val_sets(x_train, y_train, train_j, val_j)\n",
        "\n",
        "        # create a new study\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        if model_name == 'Deep Ensemble':\n",
        "          study.optimize(lambda trial: deep_ens_train_objective(trial, train_ds, val_ds, x_test, y_test), n_trials=10)\n",
        "        elif model_name == 'Improved Deep Ensemble':\n",
        "          study.optimize(lambda trial: improved_deep_ens_train_objective(trial, train_ds, val_ds, x_test, y_test), n_trials=10)\n",
        "        else:\n",
        "          study.optimize(lambda trial: inception_train_objective(trial, train_ds, val_ds, x_test, y_test), n_trials=10)\n",
        "\n",
        "\n",
        "        best_trial = study.best_trial\n",
        "        accuracy = best_trial.value\n",
        "\n",
        "      # # evaluate model\n",
        "      if model_name == 'Deep Ensemble':\n",
        "          accuracy, TPR, FPR, precision, roc_auc, auc_PR_curve, training_time, inference_time = deep_ens_evaluate_objective(best_trial, train_ds, val_ds, x_test, y_test)\n",
        "      elif model_name == 'Improved Deep Ensemble':\n",
        "        accuracy, TPR, FPR, precision, roc_auc, auc_PR_curve, training_time, inference_time = improved_deep_ens_evaluate_objective(best_trial, train_ds, val_ds, x_test, y_test)\n",
        "      else:\n",
        "        accuracy, TPR, FPR, precision, roc_auc, auc_PR_curve, training_time, inference_time = inception_evaluate_objective(best_trial, train_ds, val_ds, x_test, y_test)\n",
        "\n",
        "      # report progress\n",
        "      data_row = [dataset_name, model_name, cv_counter, best_trial.params, accuracy, TPR, FPR, precision, roc_auc, auc_PR_curve, training_time, inference_time]\n",
        "      report_df.loc[len(report_df)] = data_row\n",
        "      print(\"finished cv: \" + str(cv_counter))\n",
        "      cv_counter+=1\n",
        "  return report_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9pLxIg7A67_"
      },
      "source": [
        "**Cross Validation - Deep Ensemble**\n",
        "\n",
        "In this section we performed the cross validation for the Deep Ensemble model with the 20 different datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR6tL4rqA02s"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "report_df = initiate_report_df()\n",
        "for i in range (0, 20):\n",
        "  dataset_name = 'CIFAR-10_subset_' + str(i) \n",
        "  report_df = nested_cross_validation(X_subsets[i], y_subsets[i], dataset_name, 'Deep Ensemble', report_df)\n",
        "\n",
        "report_df.to_csv('drive/My Drive/Colab Notebooks/deep_ensemble_report.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUcitFcNWYpR"
      },
      "source": [
        "**Cross Validation - Improved Deep Ensemble**\n",
        "\n",
        "In this section we performed the cross validation for the Improved Deep Ensemble model with the 20 different datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSKossSBSoj1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "report_df = initiate_report_df()\n",
        "for i in range (0, 20):\n",
        "  dataset_name = 'CIFAR-10_subset_' + str(i) \n",
        "  report_df = nested_cross_validation(X_subsets[i], y_subsets[i], dataset_name, 'Improved Deep Ensemble', report_df)\n",
        "\n",
        "report_df.to_csv('drive/My Drive/Colab Notebooks/improved_deep_ensemble_report.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLLtkrIgWoG-"
      },
      "source": [
        "**Cross Validation - Inception V3**\n",
        "\n",
        "In this section we performed the cross validation for the Inception model with the 20 different datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3VpJQg1BDq6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "report_df = initiate_report_df()\n",
        "for i in range (0, 20):\n",
        "  dataset_name = 'CIFAR-10_subset_' + str(i) \n",
        "  report_df = nested_cross_validation(X_subsets[i], y_subsets[i], dataset_name, 'Inception', report_df)\n",
        "\n",
        "report_df.to_csv('drive/My Drive/Colab Notebooks/inception_report.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzAm-eVBp4O-"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VQrFUXsqOiQ"
      },
      "source": [
        "**Cross Validation Results:**\n",
        "\n",
        "First, we saved the results for each algorithm on different csv and combined them manually to one csv file - full_report.\n",
        "\n",
        "In this section we'll read the full csv report that we wrote during the CV of the different algorithms and datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKriSHLUp-eZ",
        "outputId": "37140b96-2e8a-4920-bf20-ca51d1c139b8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "full_report = pd.read_csv('drive/MyDrive/ML-Project/full_report.csv')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmxk-EKdvFYx"
      },
      "source": [
        "We will calculate the average AUC of the 10 cross validation results for each pair of algorithm and dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dTiUxCdzrlVa",
        "outputId": "f77add15-e5c6-412c-9c30-ad0c6e693bf0"
      },
      "source": [
        "mean_auc_df = full_report.groupby(['Dataset Name', 'Algorithm Name'])['AUC'].mean().reset_index()\n",
        "mean_auc_df"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset Name</th>\n",
              "      <th>Algorithm Name</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CIFAR-10_subset_0</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.568848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CIFAR-10_subset_0</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.503322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CIFAR-10_subset_0</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.497634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CIFAR-10_subset_1</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.559002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CIFAR-10_subset_1</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.518408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CIFAR-10_subset_1</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.506798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CIFAR-10_subset_10</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.529935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CIFAR-10_subset_10</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.512779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CIFAR-10_subset_10</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.510439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CIFAR-10_subset_11</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.572699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CIFAR-10_subset_11</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.509555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CIFAR-10_subset_11</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.504866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CIFAR-10_subset_12</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.557418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>CIFAR-10_subset_12</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.518412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>CIFAR-10_subset_12</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.490063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CIFAR-10_subset_13</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.546148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>CIFAR-10_subset_13</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.530200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CIFAR-10_subset_13</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.504570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>CIFAR-10_subset_14</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.554854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>CIFAR-10_subset_14</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.510778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>CIFAR-10_subset_14</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.498819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>CIFAR-10_subset_15</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.566937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>CIFAR-10_subset_15</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.503063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>CIFAR-10_subset_15</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.503233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>CIFAR-10_subset_16</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.563670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>CIFAR-10_subset_16</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.505549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>CIFAR-10_subset_16</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.502978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>CIFAR-10_subset_17</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.542326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>CIFAR-10_subset_17</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.506868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>CIFAR-10_subset_17</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.497028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>CIFAR-10_subset_18</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.561218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>CIFAR-10_subset_18</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.522136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>CIFAR-10_subset_18</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.454707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>CIFAR-10_subset_19</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.537161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>CIFAR-10_subset_19</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.514663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>CIFAR-10_subset_19</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.495751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>CIFAR-10_subset_2</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.577004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>CIFAR-10_subset_2</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.499388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>CIFAR-10_subset_2</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.512214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>CIFAR-10_subset_3</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.545011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>CIFAR-10_subset_3</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.503890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>CIFAR-10_subset_3</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.504474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>CIFAR-10_subset_4</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.536355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>CIFAR-10_subset_4</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.516113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>CIFAR-10_subset_4</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.514906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>CIFAR-10_subset_5</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.519221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>CIFAR-10_subset_5</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.517628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>CIFAR-10_subset_5</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.501904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>CIFAR-10_subset_6</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.537657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>CIFAR-10_subset_6</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.513045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>CIFAR-10_subset_6</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.499067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>CIFAR-10_subset_7</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.514204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>CIFAR-10_subset_7</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.522477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>CIFAR-10_subset_7</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.500967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>CIFAR-10_subset_8</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.548913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>CIFAR-10_subset_8</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.499300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>CIFAR-10_subset_8</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.494903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>CIFAR-10_subset_9</td>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>0.548754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>CIFAR-10_subset_9</td>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.536324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>CIFAR-10_subset_9</td>\n",
              "      <td>Inception</td>\n",
              "      <td>0.512764</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Dataset Name          Algorithm Name       AUC\n",
              "0    CIFAR-10_subset_0           Deep Ensemble  0.568848\n",
              "1    CIFAR-10_subset_0  Improved Deep Ensemble  0.503322\n",
              "2    CIFAR-10_subset_0               Inception  0.497634\n",
              "3    CIFAR-10_subset_1           Deep Ensemble  0.559002\n",
              "4    CIFAR-10_subset_1  Improved Deep Ensemble  0.518408\n",
              "5    CIFAR-10_subset_1               Inception  0.506798\n",
              "6   CIFAR-10_subset_10           Deep Ensemble  0.529935\n",
              "7   CIFAR-10_subset_10  Improved Deep Ensemble  0.512779\n",
              "8   CIFAR-10_subset_10               Inception  0.510439\n",
              "9   CIFAR-10_subset_11           Deep Ensemble  0.572699\n",
              "10  CIFAR-10_subset_11  Improved Deep Ensemble  0.509555\n",
              "11  CIFAR-10_subset_11               Inception  0.504866\n",
              "12  CIFAR-10_subset_12           Deep Ensemble  0.557418\n",
              "13  CIFAR-10_subset_12  Improved Deep Ensemble  0.518412\n",
              "14  CIFAR-10_subset_12               Inception  0.490063\n",
              "15  CIFAR-10_subset_13           Deep Ensemble  0.546148\n",
              "16  CIFAR-10_subset_13  Improved Deep Ensemble  0.530200\n",
              "17  CIFAR-10_subset_13               Inception  0.504570\n",
              "18  CIFAR-10_subset_14           Deep Ensemble  0.554854\n",
              "19  CIFAR-10_subset_14  Improved Deep Ensemble  0.510778\n",
              "20  CIFAR-10_subset_14               Inception  0.498819\n",
              "21  CIFAR-10_subset_15           Deep Ensemble  0.566937\n",
              "22  CIFAR-10_subset_15  Improved Deep Ensemble  0.503063\n",
              "23  CIFAR-10_subset_15               Inception  0.503233\n",
              "24  CIFAR-10_subset_16           Deep Ensemble  0.563670\n",
              "25  CIFAR-10_subset_16  Improved Deep Ensemble  0.505549\n",
              "26  CIFAR-10_subset_16               Inception  0.502978\n",
              "27  CIFAR-10_subset_17           Deep Ensemble  0.542326\n",
              "28  CIFAR-10_subset_17  Improved Deep Ensemble  0.506868\n",
              "29  CIFAR-10_subset_17               Inception  0.497028\n",
              "30  CIFAR-10_subset_18           Deep Ensemble  0.561218\n",
              "31  CIFAR-10_subset_18  Improved Deep Ensemble  0.522136\n",
              "32  CIFAR-10_subset_18               Inception  0.454707\n",
              "33  CIFAR-10_subset_19           Deep Ensemble  0.537161\n",
              "34  CIFAR-10_subset_19  Improved Deep Ensemble  0.514663\n",
              "35  CIFAR-10_subset_19               Inception  0.495751\n",
              "36   CIFAR-10_subset_2           Deep Ensemble  0.577004\n",
              "37   CIFAR-10_subset_2  Improved Deep Ensemble  0.499388\n",
              "38   CIFAR-10_subset_2               Inception  0.512214\n",
              "39   CIFAR-10_subset_3           Deep Ensemble  0.545011\n",
              "40   CIFAR-10_subset_3  Improved Deep Ensemble  0.503890\n",
              "41   CIFAR-10_subset_3               Inception  0.504474\n",
              "42   CIFAR-10_subset_4           Deep Ensemble  0.536355\n",
              "43   CIFAR-10_subset_4  Improved Deep Ensemble  0.516113\n",
              "44   CIFAR-10_subset_4               Inception  0.514906\n",
              "45   CIFAR-10_subset_5           Deep Ensemble  0.519221\n",
              "46   CIFAR-10_subset_5  Improved Deep Ensemble  0.517628\n",
              "47   CIFAR-10_subset_5               Inception  0.501904\n",
              "48   CIFAR-10_subset_6           Deep Ensemble  0.537657\n",
              "49   CIFAR-10_subset_6  Improved Deep Ensemble  0.513045\n",
              "50   CIFAR-10_subset_6               Inception  0.499067\n",
              "51   CIFAR-10_subset_7           Deep Ensemble  0.514204\n",
              "52   CIFAR-10_subset_7  Improved Deep Ensemble  0.522477\n",
              "53   CIFAR-10_subset_7               Inception  0.500967\n",
              "54   CIFAR-10_subset_8           Deep Ensemble  0.548913\n",
              "55   CIFAR-10_subset_8  Improved Deep Ensemble  0.499300\n",
              "56   CIFAR-10_subset_8               Inception  0.494903\n",
              "57   CIFAR-10_subset_9           Deep Ensemble  0.548754\n",
              "58   CIFAR-10_subset_9  Improved Deep Ensemble  0.536324\n",
              "59   CIFAR-10_subset_9               Inception  0.512764"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QkA-J_6vYFm"
      },
      "source": [
        "Make a list of the AUC scores for each algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVyYQeDjsIH9"
      },
      "source": [
        "deep_ensemble_auc = mean_auc_df.loc[mean_auc_df['Algorithm Name']  == \"Deep Ensemble\"][\"AUC\"].to_list()\n",
        "improved_deep_ensemble_auc = mean_auc_df.loc[mean_auc_df['Algorithm Name']  == \"Improved Deep Ensemble\"][\"AUC\"].to_list()\n",
        "inception_auc = mean_auc_df.loc[mean_auc_df['Algorithm Name']  == \"Inception\"][\"AUC\"].to_list()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2rvA8JQuL_W"
      },
      "source": [
        "**Friedman Test:**\n",
        "\n",
        "In this section we'll use Friedman test in order to check if all the algorithms perform the same (H0) or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pCrCX5tuOvR",
        "outputId": "33829b42-bcbf-45f8-bb58-efaec0342339"
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "# perform Friedman Test\n",
        "stats.friedmanchisquare(deep_ensemble_auc, improved_deep_ensemble_auc, inception_auc)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FriedmanchisquareResult(statistic=32.69999999999999, pvalue=7.930219729907684e-08)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id08cpRn-4gq"
      },
      "source": [
        "**Post-Hoc Test:**\n",
        "\n",
        "As we can see, the H0 hypothesis was rejected (P-value<0.05). We will perform the Post-Hoc test in order to test the differences between the algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "bRf1QfPLGJPi",
        "outputId": "fa6f65cd-deeb-4b18-f857-9b04bc4a22f9"
      },
      "source": [
        "!pip install scikit-posthocs\n",
        "import scikit_posthocs as sp\n",
        "\n",
        "# perform Post-Hoc Test\n",
        "sp.posthoc_nemenyi_friedman(mean_auc_df, y_col='AUC', block_col='Dataset Name', group_col='Algorithm Name', melted=True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Deep Ensemble</th>\n",
              "      <th>Improved Deep Ensemble</th>\n",
              "      <th>Inception</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Deep Ensemble</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002589</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Improved Deep Ensemble</th>\n",
              "      <td>0.002589</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.046567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Inception</th>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.046567</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Deep Ensemble  Improved Deep Ensemble  Inception\n",
              "Deep Ensemble                1.000000                0.002589   0.001000\n",
              "Improved Deep Ensemble       0.002589                1.000000   0.046567\n",
              "Inception                    0.001000                0.046567   1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZu9pcC8LyX2"
      },
      "source": [
        "We can also see the results using heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Mxca7gO9I49W",
        "outputId": "9edc0387-19c9-47c5-e8ca-f0668036a9fb"
      },
      "source": [
        "pc = sp.posthoc_conover(mean_auc_df, val_col='AUC', group_col='Algorithm Name')\n",
        "heatmap_args = {'linewidths': 0.25, 'linecolor': '0.5', 'clip_on': False, 'square': True, 'cbar_ax_bbox': [0.80, 0.35, 0.04, 0.3]}\n",
        "sp.sign_plot(pc, **heatmap_args)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<matplotlib.axes._subplots.AxesSubplot at 0x7f5428f8b050>,\n",
              " <matplotlib.colorbar.ColorbarBase at 0x7f541f6e5e50>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJBiDFFLL3Mn"
      },
      "source": [
        "As we can see all two pairs of algorithms perform significantly different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUH9Nv6b3S0X"
      },
      "source": [
        "**Evaluation - improved algorithm**\n",
        "\n",
        "In this section, we will compare between the running times of the Deep Ensemble model and the Improved Deep Ensemble model in order to see if we managed to achieve our main purpose in the suggested algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ckdmZdmH3aLz",
        "outputId": "16975f7c-ca28-4380-bf61-7925b2209142"
      },
      "source": [
        "mean_train_time_df = full_report.groupby(['Algorithm Name'])['Training Time'].mean().reset_index()\n",
        "mean_train_time_df\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm Name</th>\n",
              "      <th>Training Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>12.256998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>6.786281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Inception</td>\n",
              "      <td>6.583463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Algorithm Name  Training Time\n",
              "0           Deep Ensemble      12.256998\n",
              "1  Improved Deep Ensemble       6.786281\n",
              "2               Inception       6.583463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "orM6lBH13_iN",
        "outputId": "6939c0b1-3594-40af-a216-fad42dd6baaa"
      },
      "source": [
        "mean_inference_time_df = full_report.groupby(['Algorithm Name'])['Inference Time'].mean().reset_index()\n",
        "mean_inference_time_df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm Name</th>\n",
              "      <th>Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Deep Ensemble</td>\n",
              "      <td>1.050858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Improved Deep Ensemble</td>\n",
              "      <td>0.600875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Inception</td>\n",
              "      <td>1.206252</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Algorithm Name  Inference Time\n",
              "0           Deep Ensemble        1.050858\n",
              "1  Improved Deep Ensemble        0.600875\n",
              "2               Inception        1.206252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLtzBELD4wdS"
      },
      "source": [
        "From the results of the mean training time and inference time, we can see that we did managed to improve the running time using the Boosting technique.  "
      ]
    }
  ]
}